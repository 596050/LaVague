{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from lavague.contexts.openai import OpenaiContext\n",
    "\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "\n",
    "\n",
    "embed_model = GeminiEmbedding(model_name=\"models/text-embedding-004\")\n",
    "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "context = OpenaiContext(llm=\"gpt-4o\")\n",
    "\n",
    "context.llm = llm\n",
    "context.embedding = embed_model\n",
    "\n",
    "mm_llm = OpenAIMultiModal(model=\"gpt-4o\", temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://huggingface.co/tiiuae/falcon-11B\"\n",
    "instruction = \"How was falcon-11B trained?\"\n",
    "\n",
    "#url = \"https://fr.wikipedia.org/wiki/Yann_Le_Cun\"\n",
    "# instruction = \"where does Yann LeCun work ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "import trafilatura\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "\n",
    "html = requests.get(url).content\n",
    "\n",
    "#write html in a file\n",
    "with open('example.html', 'wb') as f:\n",
    "    f.write(html)\n",
    "\n",
    "state = {\n",
    "    'html_file': 'example.html',\n",
    "}\n",
    "\n",
    "\n",
    "def extract_text_content(instruction, html_file):\n",
    "    \"\"\"\n",
    "    Extract the text content of the HTML page\n",
    "    {\n",
    "        \"user\": \"Use the content of the HTML page to answer the question 'How was falcon-11B trained?'\",\n",
    "        \"agent\": \"I need to use the 'extract_text_content' tool to get information about how Falcon-11B was trained.\",\n",
    "        \"action\": \"extract_text_content\",\n",
    "        \"action_input\": {\n",
    "            \"instruction\": \"How was Falcon-11B trained?\",\n",
    "            \"html_file\": \"example.html\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Use the content of the HTML page to answer the question 'What are the main types of renewable energy?'\",\n",
    "        \"agent\": \"I need to use the 'extract_text_content' tool to get information about the main types of renewable energy.\",\n",
    "        \"action\": \"extract_text_content\",\n",
    "        \"action_input\": {\n",
    "            \"instruction\": \"How was Falcon-11B trained?\",\n",
    "            \"html_file\": \"example.html\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Use the content of Yann LeCun's Wikipedia page to make a summary of his life.\",\n",
    "        \"agent\": \"I need to use the 'extract_text_content' tool to get information from Yann LeCun's Wikipedia page to make a summary of his life.\",\n",
    "        \"action\": \"extract_text_content\",\n",
    "        \"action_input\": {\n",
    "            \"instruction\": \"How was Falcon-11B trained?\",\n",
    "            \"html_file\": \"example.html\"\n",
    "        },\n",
    "    }\n",
    "    \"\"\"\n",
    "    with open(html_file, 'rb') as f:\n",
    "        html = f.read()\n",
    "        os.remove(html_file)\n",
    "    page_content = trafilatura.extract(html)\n",
    "    documents = [Document(text=page_content)]\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    query_engine = index.as_query_engine(llm)\n",
    "    output = query_engine.query(instruction).response\n",
    "    return output\n",
    "\n",
    "extract_tool = FunctionTool.from_defaults(fn=extract_text_content, return_direct=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use the 'extract_text_content' tool to get the code snippet to use Falcon11-b.\n",
      "Action: extract_text_content\n",
      "Action Input: {'instruction': 'Extract the code snippet to use Falcon11-b', 'html_file': 'example.html'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: ```python\n",
      "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
      "import transformers\n",
      "import torch\n",
      "\n",
      "model = \"tiiuae/falcon-11B\"\n",
      "tokenizer = AutoTokenizer.from_pretrained(model)\n",
      "pipeline = transformers.pipeline(\n",
      "    \"text-generation\",\n",
      "    model=model,\n",
      "    tokenizer=tokenizer,\n",
      "    torch_dtype=torch.bfloat16,\n",
      "    device_map=\"auto\",\n",
      ")\n",
      "sequences = pipeline(\n",
      "    \"Can you explain the concepts of Quantum Computing?\",\n",
      "    max_length=200,\n",
      "    do_sample=True,\n",
      "    top_k=10,\n",
      "    num_return_sequences=1,\n",
      "    eos_token_id=tokenizer.eos_token_id,\n",
      ")\n",
      "for seq in sequences:\n",
      "    print(f\"Result: {seq['generated_text']}\")\n",
      "``` \n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "agent = ReActAgent.from_tools([extract_tool], llm=llm, verbose=True)\n",
    "answer = agent.chat(\"Extract the code snippet to use Falcon11-b\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lavague-agent2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
